
The ease with which we recognize a face, understand spoken words, read handwriten characters, identify our car keys in our pocket by feel, and decide whether an apple is ripe by its smell belies the astoundingly complex processes that underlie these acts of pattern recognition. Pattern recognition — the act of taking in raw data and taking an action based on the "category" of the pattern — has been crucial for our survival, and over the past tens of millions of years we have evolved highly sophisticated neural and cognitive systems for such tasks.

## 1.1 Machine Perception
It is natural that we should seek to design and build machines that can recognize patterns. From automated speech recognition, fingerprint identification optical character recognition, DNA sequence identification and much more, it is clear that reliable, accurate pattern recognition by machine would be immensely useful. Moreover, in solving the myriad problems required to build such systems, we gain deeper understanding and appreciation for pattern recognition systems in the natural world — most particulary in humans. For some applications, such as speech and visual recognition, our design efforts may in fact be influenced by knowledge of how these are solved in nature, both in the algorithms we employ and the design of special purpose hardware.

## 1.2 An Example
To illustrate the complexity of some of the types of problems involved, let us consider the following imaginary and somewhat fanciful example. Suppose that a fish packing plant wants to automate the process of sorting incoming fish on a conveyor belt according to species. As a pilot project it is decided to try to separate sea bass from salmon using optical sensing. We set up a camera, take some sample images and begin to note some physical diffrences between the two types of fish — length, lightness, width, number and shape of fins, posiion of the mouth, and so on — and these suggest *features* to explore for use in our classifier. We also notice noise or variiations in the images — variations in lighting, position of the fish on the conveyor, even "static" due to he electronics of the camera itself.

Given that there truly are differences between the population of sea bass and that of salmon, we view them as having different *models* — different descriptions, which are typically mathematical in form. The overarching goal and approach in pattern classification is to hyporhesize the class of these models, process the sensed data to eliminate noise (not due to the models), and for any sensed pattern choose the model that corresponds best. Any technique that further this aim should be in the conceptual toolbox of the designer of pattern recognition systems. 
— MODEL —

Our prototype system to perform this very specific task might well have the form shown inf Fig. 1.1. First the camera captures an image of the fish.
— PREPROCESSING —
Next, the camera's signals are preprocessed to simplify subsequent operations without loosing relevant information. In particular, we might use a segmentation operation in which the images of different fish are somehow isolated from one another and from the background. 
— SEGMENTATION —
The infromation from a single fish is then sent to a *feature extractor* , whose purpose is to reduce the data by measuring certain "features" or "properties." These features (or, more precisely, the values of these  features) are then passed to a classifier that evaluates the evidence presented and makes a final decision as to the species.
 — FEATURE EXTRACTION —

The preprocessor might automatically adjust for average light level, or threshold the image to remove the background of the conveyor belt, and so forth. For the moment let us pass over how the images of the fish might be segmented and consider how the feature extractor and classifier might be designed. Suppose somebody at the fish plant tells us that a sea bass is generally longer than a salmon. These, then, give us our tentative models for the fish: sea bass have some typical length, and this is greater than that for salmon. Then length becomes an obvious feature, and we might attempt to classify the fish merely by seeing whether or not the length *l* of a fish exceeds some critical value *l*$^*$. To choose *l*$^*$ we could obtain some *design* or *training samples* of the different types of fish, (somehow) make length measurements, and inspect the results.
**— TRAINING SAMPLES —** 

Suppose that we do this, and obtain the histograms shown in Fig 1.2. These disappointing histogrmas bear out the statement that sea base are somewhat longer than salmon, ov average, but it is clear that this single criterion is quite poor; no matter how we choose *l*$^*$, we cannot reliably separte sea bass from salmon by length alone.
Discouraged, butunderterred by these unpromising results, we try another feature — the average lightness of the fish scales. Now we are very careful to eliminate cariations in illumination, since they can only obsecure the models and corrupt our new classifier. The resulting histograms, shown in Fig. 1.3, are much more satisfactory — the classes are much better seperated.

So far we have tacity assurned that the consequences of our actions are equally costly: deciding the fish was a sea bass when in fact it was a salmon was just as undesirable as the converse. Such a symmetry in the cost is often, but not invariably the case. For instance, as a fish packing company we may know that our customers easily accept occasional pieces of tasty salmon in their cans labeld "sea bass," but they object vigorously if a piece of sea bass appears in their cans labeled "salmon". If we want to stay in business, we should adjust our decision boundary to avoid antagonizing our customers, even if it means that more salmon makes its way into the cans of sea bass. In this case, then we should move our decision boundary $x^*$ to smaller values of lightness, thereby reducing the number of sea bass that are classified as salmon (Fig. 1.3). The more our customers object to getting sea bass with their salmon — i.e., the more costly this type of error — the lower we should set the decision threshold $x^*$ in Fig. 1.3.

Such consigerations suggest that there is an overall single cost associated with our decision, and our true task is to make a decision rule (i.e., set a decision boundary) so as to minimize such a cost. This is the central task of decision theory of which pattern classification is perhaps the most important subfield.
— DECISION THEORY —

Even if we know the costs associated with our decisions and choose the optimal decision boundary $x^*$, we may be dissatisfied with the resulting performance. Our first impulse might be to seek yet a different feature on which to separate the fish. Let us assume, though, that no other single visual feature yields better poerformance than that based on lightness. To improve recognition, then, we must resort to the use of more than one feature at a time.
In our search for other features, we might try to capitalize on the obeservation that sea bass are typically wider than salmon. Now we have two features for classifying fish — the lightness $x_1$ and the width $x_2$. If we ignore how these features might be measured in practice, we realize that the feature extractor has thus reduced the image of each fish to a point of feature vector x in a two-dimensional feature space, where
$$x = [ x_1 \ x_2]$$
Our problem now is to partition the feature space into two refions, where for all patterns in one region we will call the fish a sea bass, and all points in the other we call it a salmon. Suppose that we measure the feature vectors for our samples and obtain the scattering of points shown in Fig. 1.4. This plot suggests the follwing rule for seperating the fish: Classify the fish as sea bass if its feature vector falls above the decision boundary shown, and as salmon otherwise.
This rule appears to do a good job of separating our samples and suggests that perhaps incorporating yet more features would be desirable. Besides the lightness and width of the fish, we might include some shape parameter, suc as the vertex angle of the dorsal fin, or the placement of the eyes (as expressed as a proportion of the mout-to-tail distance), and so on. How do we know beforehand which of these features will work best? Some features might be redundant: for instance of the eyes color of all fish correlated perfectly with width, then classification performance need not be improved if we also include eye color as a feature. Even if the difficulty or computational cost in attaining more features is of no concern, might we ever have too many features?

![](https://i.imgur.com/MmiV5W0.png)
